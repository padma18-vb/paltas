{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/padmavenkatraman/Documents/StrongLensing/silver/lib/python3.11/site-packages/numba/core/decorators.py:262: NumbaDeprecationWarning: numba.generated_jit is deprecated. Please see the documentation at: https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-generated-jit for more information and advice on a suitable replacement.\n",
      "  warnings.warn(msg, NumbaDeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import paltas\n",
    "from astropy.visualization import simple_norm\n",
    "import visualization_utils\n",
    "from paltas import generate\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "SMALL_SIZE = 16\n",
    "MEDIUM_SIZE = 18\n",
    "BIGGER_SIZE = 20\n",
    "\n",
    "\n",
    "plt.rc('font', size=SMALL_SIZE)          # controls default text sizes\n",
    "plt.rc('axes', titlesize=BIGGER_SIZE)    # fontsize of the axes title\n",
    "plt.rc('axes', labelsize=MEDIUM_SIZE)    # fontsize of the x and y labels\n",
    "plt.rc('xtick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('ytick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('legend', fontsize=SMALL_SIZE)    # legend fontsize\n",
    "plt.rc('figure', titlesize=BIGGER_SIZE)  # fontsize of the figure title\n",
    "\n",
    "%matplotlib inline\n",
    "root_path = paltas.__path__[0][:-7]\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### paltas PSF library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# psf_im = np.load('data/psf_images.npy', mmap_mode='r+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# psf_im_i = psf_im[:, 1, :, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # index = np.random.randint(0, psf_im_i.shape[0])\n",
    "# index = 0\n",
    "# psf_kernels = psf_im_i[index, :, :]\n",
    "# psf_kernels[psf_kernels<0] = 0\n",
    "# plt.imshow(psf_kernels);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# psf_sums = np.sum(psf_im_i,axis=(1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# psf_sums = psf_sums.reshape(-1,1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalized = psf_im_i/psf_sums\n",
    "# normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "# normalized = tf.constant(normalized)\n",
    "# pad_tns = tf.constant([[0, 0],[0,1],[0,1]])\n",
    "# # -----------padding: ^first_dim^\n",
    "# # ------------------------padding: ^second_dim^\n",
    "# # ---------------------------------------padding: ^third_dim^\n",
    "\n",
    "# # Generating padded Tensor\n",
    "# res = tf.pad(normalized, pad_tns, mode ='CONSTANT', constant_values=0)\n",
    "# print(res.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.save('data/norm_resize_psf.npy', res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #plt.hist(normalized[0, :, 17], alpha=0.5)\n",
    "\n",
    "# #plt.hist(normalized[0, :, 16], alpha = 0.5)\n",
    "# plt.plot(normalized[0, :, 15], alpha=0.5, label=15)\n",
    "# plt.plot(normalized[0, :, 16], alpha=0.5, label=16)\n",
    "# plt.plot(normalized[0, :, 17], alpha=0.5, label=17)\n",
    "# plt.plot(normalized[0, :, 18], alpha=0.5, label=18)\n",
    "# plt.axvline(32//2)\n",
    "# plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #plt.hist(normalized[0, :, 17], alpha=0.5)\n",
    "\n",
    "# #plt.hist(normalized[0, :, 16], alpha = 0.5)\n",
    "# plt.plot(normalized[0, 15, :], alpha=0.5, label=15)\n",
    "# plt.plot(normalized[0, 16, :], alpha=0.5, label=16)\n",
    "# plt.plot(normalized[0, 17, :], alpha=0.5, label=17)\n",
    "# plt.plot(normalized[0, 18, :], alpha=0.5, label=18)\n",
    "# plt.axvline(32//2)\n",
    "# plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots(1, 1, figsize=(6, 6))\n",
    "# # ax[0].imshow(normalized_resized[0, :, :])\n",
    "# ax.imshow(normalized[0, :, :])\n",
    "# # ax[0].set_title('resized PSF: 31x31')\n",
    "# ax.set_title('original PSF: 32x32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.hist(psf_sums.flatten(), density=True, bins=100);\n",
    "# plt.title(\"PSF Sum Distribution\")\n",
    "# plt.xlabel(\"Sum of pixel in PSF kernel\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_file = 'config_LSST'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from paltas.Configs.config_handler import ConfigHandler\n",
    "\n",
    "# We'll pass one of our example Configs in\n",
    "config_handler = ConfigHandler(os.path.join(root_path,'paltas/notebooks/config_LSST.py'))\n",
    "\n",
    "# First let's get the lenstronomy model lists, kwargs lists, and redshift lists.\n",
    "kwargs_model, kwargs_params = config_handler.get_lenstronomy_models_kwargs()\n",
    "\n",
    "# We can see what keys are returned, and inspect the lens models in particular\n",
    "print('Available Keys:')\n",
    "print(kwargs_model.keys())\n",
    "print(kwargs_params.keys())\n",
    "print('')\n",
    "\n",
    "print('lens_model_list')\n",
    "print(kwargs_model['lens_model_list'])\n",
    "print('kwargs_lens')\n",
    "print()\n",
    "print(kwargs_params['kwargs_lens_light'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kwargs_params['kwargs_lens'][0]['theta_E']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img, prop = config_handler.draw_image(new_sample=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# command = f'python3 ../paltas/generate.py {config_file}.py generated_images/test/{config_file} --n 1556 --tf_record'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.system(command = command)\n",
    "config_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "command = f'python3 ../paltas/generate.py {config_file}.py generated_images/train_with_lens/{config_file} --n 100000 --tf_record --h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.system(command = command)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import paltas.Analysis.dataset_generation as dg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving 100000 files into the tf record\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100000/100000 [00:05<00:00, 18338.31it/s]\n"
     ]
    }
   ],
   "source": [
    "dg.generate_tf_record('generated_images/train_with_lens/config_LSST/',['main_deflector_parameters_theta_E',\n",
    "\t'main_deflector_parameters_gamma1','main_deflector_parameters_gamma2',\n",
    "\t'main_deflector_parameters_gamma','main_deflector_parameters_e1',\n",
    "\t'main_deflector_parameters_e2','main_deflector_parameters_center_x',\n",
    "\t'main_deflector_parameters_center_y'],'generated_images/train_with_lens/config_LSST/metadata.csv',\n",
    "\t'generated_images/train_with_lens/config_LSST/data.tfrecord',h5=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import paltas.Sampling.distributions as dist\n",
    "from scipy.stats import norm, truncnorm, uniform\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.hist(norm(loc=0,scale=0.5).rvs(size=1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_file_path = f'generated_images/no_lens/{config_file}/'\n",
    "\n",
    "file_list = [os.path.join(config_file_path, i) for i in os.listdir(config_file_path)]\n",
    "names = np.arange(100).astype(str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(f'generated_images/no_lens/{config_file}/metadata.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_index = np.random.randint(0, 100 - 24)\n",
    "picked_files = file_list[start_index:start_index + 24]\n",
    "picked_names = names[start_index:start_index + 24]\n",
    "picked_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "visualization_utils.matrix_plot_from_npy(picked_files,names=picked_names,dim=(3,8),\n",
    "                                         save_name='lsst.png',stretch = 'asinh',asinh_a = 0.1,\n",
    "                                         annotate=False)\n",
    "plt.show()\n",
    "# visualization_utils.matrix_plot_from_npy(picked_files,names=picked_names,dim=(3,8),\n",
    "#                                          save_name='lsst.png',asinh_a = 0.1, max_cut = 70, annotate=True)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# weights = sorted(os.listdir('train_results/model_weights'))\n",
    "# losses = pd.read_csv('train_results/train.csv', index_col=0)\n",
    "# file_list_bad= []\n",
    "# num_files = len(weights)\n",
    "# for i in range (num_files):\n",
    "# # weights[0][-12:-8]\n",
    "#     print(weights[i])\n",
    "#     ind = int(weights[i][1:3])\n",
    "#     ls = float(weights[i][-12:-8])\n",
    "#     valloss = np.round(losses.loc[ind-1, 'val_loss'], 2)\n",
    "#     # print(type(valloss), type(ls))\n",
    "#     if not np.isclose(valloss,ls):\n",
    "#         print(ind, 'latest loss: ', valloss, 'loss_on_file: ', ls)\n",
    "#         file = f'train_results/model_weights/{weights[i]}'\n",
    "#         file_list_bad.append(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# losses = pd.read_csv('train_results/train.csv', index_col=0)\n",
    "# epochs = len(losses['val_loss'])\n",
    "# losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# losses = pd.read_csv('train_results/train.csv', index_col=0)\n",
    "# epochs = losses.index\n",
    "# plt.plot(epochs, losses['loss'], label='Training Loss')\n",
    "# plt.plot(epochs, losses['val_loss'], label='Validation Loss')\n",
    "# plt.legend()\n",
    "# plt.title(\"Training Loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.system(command = f'python ../paltas/Analysis/train_model.py lsst_train.py --tensorboard_dir NLNORM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "silver",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
